{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "664bd94f-0b5e-4cba-b605-b0ef7efdef23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import ndcg_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c7ee42e-7ea3-4035-9dfa-50ce5fab0097",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "sample_submission = pd.read_csv(r'../data/sample_submission.csv')\n",
    "\n",
    "members = pd.read_csv('../data/members.csv')\n",
    "songs = pd.read_csv('../data/songs.csv')\n",
    "song_extra_info = pd.read_csv('../data/song_extra_info.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbb5b7f-c37b-4d26-8421-375b7d88109d",
   "metadata": {},
   "source": [
    "## Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8247bd9c-a586-45c7-82ad-a276f697c146",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureGenerator:\n",
    "    def __init__(self, train):\n",
    "        self.train = train.copy()\n",
    "        \n",
    "        self.artist_target = None\n",
    "        self.composer_target = None\n",
    "        self.lyricist_target = None\n",
    "        \n",
    "        self.total_counts = None\n",
    "        self.genre_counts = None\n",
    "        self.tab_counts = None\n",
    "        self.screen_counts = None\n",
    "        \n",
    "        self.user_features = None\n",
    "        self.item_features = None\n",
    "    \n",
    "    def conditional_probabilities(self, predictor, condition, data):\n",
    "        total_counts = data.groupby(condition).size().reset_index(name='count')\n",
    "        predictor_counts = data.groupby([condition, predictor]).size().reset_index(name=f'{predictor}_count')\n",
    "        predictor_counts = pd.merge(predictor_counts, total_counts, on=condition)\n",
    "        predictor_counts[f'{predictor}_probability'] = predictor_counts[f'{predictor}_count'] / predictor_counts['count']\n",
    "        predictor_counts = predictor_counts.drop([f'{predictor}_count', 'count'], axis=1)\n",
    "        return predictor_counts\n",
    "    \n",
    "    def svd_features(self):\n",
    "        user_item = self.train.groupby(['msno', 'song_id']).size().reset_index(name='count')\n",
    "        user_item['count'] = user_item['count'].astype(float)\n",
    "        \n",
    "        # unique users and songs\n",
    "        idx_user = user_item['msno'].unique()\n",
    "        idx_item = user_item['song_id'].unique()\n",
    "        \n",
    "        # hash-map to indexes\n",
    "        user_idx = {user_id: idx for idx, user_id in enumerate(idx_user)}\n",
    "        item_idx = {item_id: idx for idx, item_id in enumerate(idx_item)}\n",
    "        \n",
    "        # replace ids with indexes\n",
    "        user_item['msno'] = user_item['msno'].map(lambda x: user_idx[x])\n",
    "        user_item['song_id'] = user_item['song_id'].map(lambda x: item_idx[x])\n",
    "        \n",
    "        # sparse matrix\n",
    "        user_item_matrix = coo_matrix(\n",
    "            (user_item['count'], (user_item['msno'], user_item['song_id']))\n",
    "        )\n",
    "        user_item_matrix = user_item_matrix.tocsr()\n",
    "        \n",
    "        # compute svd features\n",
    "        u, s, vt = svds(user_item_matrix, k=20)\n",
    "        user_features = np.dot(u, np.diag(s))\n",
    "        item_features = vt\n",
    "        \n",
    "        user_features = pd.DataFrame(user_features).reset_index().rename(columns={'index': 'msno'})\n",
    "        user_features['msno'] = user_features['msno'].map(lambda x: idx_user[x])\n",
    "        \n",
    "        item_features = pd.DataFrame(item_features).reset_index().rename(columns={'index': 'song_id'})\n",
    "        item_features['song_id'] = item_features['song_id'].map(lambda x: idx_item[x])\n",
    "        \n",
    "        self.user_features = user_features\n",
    "        self.item_features = item_features\n",
    "        return\n",
    "    \n",
    "    def fit_transform(self, df):\n",
    "        df.copy()\n",
    "        df = pd.merge(df, songs, on='song_id', how='left')\n",
    "\n",
    "        # target features\n",
    "        self.artist_target = df.groupby('artist_name').agg({'target': 'mean'}) \\\n",
    "            .rename(columns={'target': 'target_artist'}).reset_index()\n",
    "        self.composer_target = df.groupby('composer').agg({'target': 'mean'}) \\\n",
    "            .rename(columns={'target': 'target_composer'}).reset_index()\n",
    "        self.lyricist_target = df.groupby('lyricist').agg({'target': 'mean'}) \\\n",
    "            .rename(columns={'target': 'target_lyricist'}).reset_index()\n",
    "        \n",
    "        df = pd.merge(df, self.artist_target, on='artist_name', how='left')\n",
    "        df = pd.merge(df, self.composer_target, on='composer', how='left')\n",
    "        df = pd.merge(df, self.lyricist_target, on='lyricist', how='left')\n",
    "\n",
    "        # conditional probabilities features\n",
    "        predictors = ['source_system_tab', 'source_screen_name', 'source_type',\n",
    "              'genre_ids', 'artist_name', 'composer', 'lyricist', 'language']\n",
    "        for predictor in predictors:\n",
    "            predictor_counts = self.conditional_probabilities(predictor, 'msno', df)\n",
    "            df = pd.merge(df, predictor_counts, on=['msno', predictor], how='left')\n",
    "            df[f'{predictor}_probability'] = df[f'{predictor}_probability'].fillna(0)\n",
    "\n",
    "        predictors = ['source_system_tab', 'source_screen_name', 'source_type']\n",
    "        for predictor in predictors:\n",
    "            predictor_counts = self.conditional_probabilities(predictor, 'song_id', df)\n",
    "            df = pd.merge(df, predictor_counts, on=['song_id', predictor], how='left', suffixes=('', '_song'))\n",
    "            df[f'{predictor}_probability_song'] = df[f'{predictor}_probability_song'].fillna(0)\n",
    "\n",
    "        # svd features\n",
    "        svd_features()\n",
    "        df = pd.merge(df, self.user_features, on='msno')\n",
    "        df = pd.merge(df, self.item_features, on='song_id')\n",
    "        \n",
    "        return df\n",
    "    def transform(self, df):\n",
    "        df = pd.merge(df, songs, on='song_id', how='left')\n",
    "        df = pd.merge(df, self.artist_target, on='artist_name', how='left')\n",
    "        df = pd.merge(df, self.composer_target, on='composer', how='left')\n",
    "        df = pd.merge(df, self.lyricist_target, on='lyricist', how='left')\n",
    "\n",
    "        predictors = ['source_system_tab', 'source_screen_name', 'source_type',\n",
    "              'genre_ids', 'artist_name', 'composer', 'lyricist', 'language']\n",
    "        for predictor in predictors:\n",
    "            predictor_counts = self.conditional_probabilities(predictor, 'msno', pd.concat((df, self.train)))\n",
    "            df = pd.merge(df, predictor_counts, on=['msno', predictor], how='left')\n",
    "            df[f'{predictor}_probability'] = df[f'{predictor}_probability'].fillna(0)\n",
    "\n",
    "        predictors = ['source_system_tab', 'source_screen_name', 'source_type']\n",
    "        for predictor in predictors:\n",
    "            predictor_counts = self.conditional_probabilities(predictor, 'song_id', pd.concat((df, self.train)))\n",
    "            df = pd.merge(df, predictor_counts, on=['song_id', predictor], how='left', suffixes=('', '_song'))\n",
    "            df[f'{predictor}_probability_song'] = df[f'{predictor}_probability_song'].fillna(0)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0ab9e05-49dd-4dbb-8e54-cd5fd887ed3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_generator = FeatureGenerator(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17875f8d-ffcf-413e-8e4d-0d5e489172ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = feature_generator.fit_transform(train)\n",
    "test = feature_generator.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0546b93-a3cc-422e-a3f8-b7652396c28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>song_id</th>\n",
       "      <th>source_system_tab</th>\n",
       "      <th>source_screen_name</th>\n",
       "      <th>source_type</th>\n",
       "      <th>target</th>\n",
       "      <th>song_length</th>\n",
       "      <th>genre_ids</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>composer</th>\n",
       "      <th>lyricist</th>\n",
       "      <th>language</th>\n",
       "      <th>target_artist</th>\n",
       "      <th>target_composer</th>\n",
       "      <th>target_lyricist</th>\n",
       "      <th>source_system_tab_probability</th>\n",
       "      <th>source_screen_name_probability</th>\n",
       "      <th>source_type_probability</th>\n",
       "      <th>genre_ids_probability</th>\n",
       "      <th>artist_name_probability</th>\n",
       "      <th>composer_probability</th>\n",
       "      <th>lyricist_probability</th>\n",
       "      <th>language_probability</th>\n",
       "      <th>source_system_tab_probability_song</th>\n",
       "      <th>source_screen_name_probability_song</th>\n",
       "      <th>source_type_probability_song</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FGtllVqz18RPiwJj/edr2gV78zirAiY/9SmYvia+kCg=</td>\n",
       "      <td>BBzumQNXUHKdEBOB7mAJuzok+IJA1c2Ryg/yzTF6tik=</td>\n",
       "      <td>explore</td>\n",
       "      <td>Explore</td>\n",
       "      <td>online-playlist</td>\n",
       "      <td>1</td>\n",
       "      <td>206471.0</td>\n",
       "      <td>359</td>\n",
       "      <td>Bastille</td>\n",
       "      <td>Dan Smith| Mark Crew</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.463158</td>\n",
       "      <td>0.49499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.161132</td>\n",
       "      <td>0.122301</td>\n",
       "      <td>0.25930</td>\n",
       "      <td>0.029577</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.530938</td>\n",
       "      <td>0.018605</td>\n",
       "      <td>0.009302</td>\n",
       "      <td>0.24186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Xumu+NIjS6QYVxDS4/t3SawvJ7viT9hPKXmf0RtLNx8=</td>\n",
       "      <td>bhp/MpSNoqoxOIB+/l8WPqu6jldth4DIpCm3ayXnJqM=</td>\n",
       "      <td>my library</td>\n",
       "      <td>Local playlist more</td>\n",
       "      <td>local-playlist</td>\n",
       "      <td>1</td>\n",
       "      <td>284584.0</td>\n",
       "      <td>1259</td>\n",
       "      <td>Various Artists</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.509851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.885852</td>\n",
       "      <td>0.885852</td>\n",
       "      <td>0.21865</td>\n",
       "      <td>0.067524</td>\n",
       "      <td>0.038585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.183280</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  \\\n",
       "0  FGtllVqz18RPiwJj/edr2gV78zirAiY/9SmYvia+kCg=   \n",
       "1  Xumu+NIjS6QYVxDS4/t3SawvJ7viT9hPKXmf0RtLNx8=   \n",
       "\n",
       "                                        song_id source_system_tab  \\\n",
       "0  BBzumQNXUHKdEBOB7mAJuzok+IJA1c2Ryg/yzTF6tik=           explore   \n",
       "1  bhp/MpSNoqoxOIB+/l8WPqu6jldth4DIpCm3ayXnJqM=        my library   \n",
       "\n",
       "    source_screen_name      source_type  target  song_length genre_ids  \\\n",
       "0              Explore  online-playlist       1     206471.0       359   \n",
       "1  Local playlist more   local-playlist       1     284584.0      1259   \n",
       "\n",
       "       artist_name              composer lyricist  language  target_artist  \\\n",
       "0         Bastille  Dan Smith| Mark Crew      NaN      52.0       0.463158   \n",
       "1  Various Artists                   NaN      NaN      52.0       0.509851   \n",
       "\n",
       "   target_composer  target_lyricist  source_system_tab_probability  \\\n",
       "0          0.49499              NaN                       0.161132   \n",
       "1              NaN              NaN                       0.885852   \n",
       "\n",
       "   source_screen_name_probability  source_type_probability  \\\n",
       "0                        0.122301                  0.25930   \n",
       "1                        0.885852                  0.21865   \n",
       "\n",
       "   genre_ids_probability  artist_name_probability  composer_probability  \\\n",
       "0               0.029577                 0.000544              0.000363   \n",
       "1               0.067524                 0.038585              0.000000   \n",
       "\n",
       "   lyricist_probability  language_probability  \\\n",
       "0                   0.0              0.530938   \n",
       "1                   0.0              0.183280   \n",
       "\n",
       "   source_system_tab_probability_song  source_screen_name_probability_song  \\\n",
       "0                            0.018605                             0.009302   \n",
       "1                            1.000000                             1.000000   \n",
       "\n",
       "   source_type_probability_song  \n",
       "0                       0.24186  \n",
       "1                       1.00000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bb263f-1eae-4b1d-884f-c2bd3bf65acf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8a2ebe-68f0-40a1-a8d7-c358ce8471e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe85214c-7f7a-4c01-a061-73bbd5416020",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['source_system_tab', 'source_screen_name', 'source_type', 'language']\n",
    "train_features = cat_features + ['song_length', 'target_artist', 'target_composer',\n",
    "                                 'target_lyricist', 'source_system_tab_probability',\n",
    "                                 'source_screen_name_probability', 'source_type_probability',\n",
    "                                 'genre_ids_probability', 'artist_name_probability',\n",
    "                                 'composer_probability', 'lyricist_probability',\n",
    "                                 'language_probability', 'source_system_tab_probability_song',\n",
    "                                 'source_screen_name_probability_song', 'source_type_probability_song']\n",
    "\n",
    "train['language'] = train['language'].map(str)\n",
    "train[cat_features] = train[cat_features].fillna('nan')\n",
    "test['language'] = test['language'].map(str)\n",
    "test[cat_features] = test[cat_features].fillna('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173c42ff-fb13-4bca-809f-f2c40efbfe6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39dae90e-033c-4c39-bd08-458584c373ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set = train_test_split(train, test_size = 0.2, random_state=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b042e45d-351c-413e-878a-77eba34fb912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set = train_set.sample(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3d3e924-7a07-4207-a5fa-8b4987c770c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "    n_estimators=1100,\n",
    "    random_seed=12,\n",
    "    verbose = 0\n",
    ").fit(train_set[train_features],\n",
    "      train_set['target'],\n",
    "      cat_features = cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56ffd22-3d9b-47a2-9637-2921e35148c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b348b09e-0d75-409e-a344-a1f33c78410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set['predict'] = model.predict_proba(val_set[train_features])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39e5bac1-7dff-4079-92a4-e7409fa18be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7570425094760802"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(val_set['target'], val_set['predict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46015f39-bda5-4bbd-932c-cfb1427c27ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = val_set.groupby('msno').apply(\n",
    "    lambda x: (float('nan') if len(x) < 2 else\n",
    "               ndcg_score(x['target'].values.reshape(1, -1),\n",
    "                          x['predict'].values.reshape(1, -1)))\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a657d3cf-c8d6-4b0b-adf9-59be922f044c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.771786404114766"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24dda747-8316-4c46-9331-d74a9460d09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['target'] = model.predict_proba(test[train_features])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6894a100-d202-472f-9a10-f073ca9e17cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(df, start_index=1):\n",
    "    index = start_index\n",
    "    while os.path.exists(rf'../predictions/pred{index}.csv'):\n",
    "        index += 1\n",
    "    df.to_csv(rf'../predictions/pred{index}.csv', index=False)\n",
    "    return rf'../predictions/pred{index}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fccdc5b-d830-4f11-9a03-313f4ba03a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../predictions/pred6.csv'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save(sample_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf841dd-e5d9-4827-8909-7eb1a56eac17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758c05e8-2ec6-440c-8be5-70bf25211c66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03c0bb0-1af2-4676-bd2a-6bad88463d25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1425a7-32c3-44a6-8376-373e8796369d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd73df5a-253d-479d-b65d-55c752fd4576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fe7dfd-dd68-46ff-9fba-836da4b60879",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708606c1-c568-4664-91a1-c7c178d6f352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d872dd-815b-4d89-963c-7f0618adc846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789fcdd-6b83-4be0-8613-dcfc46e13522",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
